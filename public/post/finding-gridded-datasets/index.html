<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Finding Gridded Datasets - GBIF Data Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="olOwOlo" />
  <meta name="description" content="EBCC Atlas of European Breeding Birds (gridded)Naturalis Biodiversity Center (NL) - Aves (not gridded)Gridded data in GBIFGridded datasets are a known problem at GBIF. Many datasets have an equally-spaced points in a regular pattern. These datasets are usually systematic national surveys or data taken from some atlas (“so-called rasterized collection designs”).
In this blog post I will describe how I found gridded dataset in GBIF." />

  <meta name="keywords" content="Hugo, theme, even" />






<meta name="generator" content="Hugo 0.46" />


<link rel="canonical" href="/post/finding-gridded-datasets/" />

<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">







<link href="/dist/even.min.css?v=3.2.0" rel="stylesheet">
<link href="/lib/fancybox/jquery.fancybox-3.1.20.min.css" rel="stylesheet">



<link rel="stylesheet" href="/css//custom.css">


<meta property="og:title" content="Finding Gridded Datasets" />
<meta property="og:description" content="EBCC Atlas of European Breeding Birds (gridded)Naturalis Biodiversity Center (NL) - Aves (not gridded)Gridded data in GBIFGridded datasets are a known problem at GBIF. Many datasets have an equally-spaced points in a regular pattern. These datasets are usually systematic national surveys or data taken from some atlas (“so-called rasterized collection designs”).
In this blog post I will describe how I found gridded dataset in GBIF." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/finding-gridded-datasets/" />



<meta property="article:published_time" content="2018-08-14T00:00:00&#43;00:00"/>

<meta property="article:modified_time" content="2018-08-14T15:47:18&#43;02:00"/>











<meta itemprop="name" content="Finding Gridded Datasets">
<meta itemprop="description" content="EBCC Atlas of European Breeding Birds (gridded)Naturalis Biodiversity Center (NL) - Aves (not gridded)Gridded data in GBIFGridded datasets are a known problem at GBIF. Many datasets have an equally-spaced points in a regular pattern. These datasets are usually systematic national surveys or data taken from some atlas (“so-called rasterized collection designs”).
In this blog post I will describe how I found gridded dataset in GBIF.">


<meta itemprop="datePublished" content="2018-08-14T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2018-08-14T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1964">



<meta itemprop="keywords" content="rstats,data quality,gridded data," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Finding Gridded Datasets"/>
<meta name="twitter:description" content="EBCC Atlas of European Breeding Birds (gridded)Naturalis Biodiversity Center (NL) - Aves (not gridded)Gridded data in GBIFGridded datasets are a known problem at GBIF. Many datasets have an equally-spaced points in a regular pattern. These datasets are usually systematic national surveys or data taken from some atlas (“so-called rasterized collection designs”).
In this blog post I will describe how I found gridded dataset in GBIF."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">GBIF Data Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">home</li>
      </a><a href="/authors/">
        <li class="mobile-menu-item">authors</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">tags</li>
      </a><a href="https://www.gbif.org/">
        <li class="mobile-menu-item">gbif.org</li>
      </a><a href="https://www.gbif.org/analytics/global">
        <li class="mobile-menu-item">global-trends</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">about</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">
	<img src= "/logo.png" alt="GBIF-analytics-blog" style ="width:20%;">
  </a>
  
	
  
  
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/authors/">authors</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.gbif.org/">gbif.org</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.gbif.org/analytics/global">global-trends</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">about</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Finding Gridded Datasets</h1>
	  
	  
      <div class="post-author">John Waller</div>

      <div class="post-meta">
        <span class="post-time"> 2018-08-14 </span>
        <div class="post-category">
            
              <a href="/categories/gbif/"> GBIF </a>
            
          </div>
        
        
      </div>
    </header>

    
    

    
    

    
    <div class="post-content">
      <script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<script src="/rmarkdown-libs/jquery/jquery.min.js"></script>
<link href="/rmarkdown-libs/leaflet/leaflet.css" rel="stylesheet" />
<script src="/rmarkdown-libs/leaflet/leaflet.js"></script>
<link href="/rmarkdown-libs/leafletfix/leafletfix.css" rel="stylesheet" />
<script src="/rmarkdown-libs/Proj4Leaflet/proj4-compressed.js"></script>
<script src="/rmarkdown-libs/Proj4Leaflet/proj4leaflet.js"></script>
<link href="/rmarkdown-libs/rstudio_leaflet/rstudio_leaflet.css" rel="stylesheet" />
<script src="/rmarkdown-libs/leaflet-binding/leaflet.js"></script>


<iframe src="https://jhnwllr.github.io/charts/franceGrid.html" style="border: none; height: 600px; width: 100%;">
</iframe>
<ul>
<li><a href="https://www.gbif.org/dataset/c779b049-28f3-4daf-bbf4-0a40830819b6">EBCC Atlas of European Breeding Birds (gridded)</a></li>
<li><a href="https://www.gbif.org/dataset/889c91a3-614f-4355-8df8-b6d0260a118c">Naturalis Biodiversity Center (NL) - Aves (not gridded)</a></li>
</ul>
<div id="gridded-data-in-gbif" class="section level3">
<h3>Gridded data in GBIF</h3>
<p>Gridded datasets are a known problem at GBIF. Many datasets have an equally-spaced points in a regular pattern. These datasets are usually systematic national surveys or data taken from some atlas (“so-called rasterized collection designs”).</p>
<blockquote>
<p>In this blog post I will describe how I found gridded dataset in GBIF.</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/jhnwllr/charts/master/gridSnap.gif" width="60%" height="60%"
style="display: block;margin-left: auto;margin-right: auto;"/></p>
</div>
<div id="what-is-the-problem" class="section level3">
<h3>What is the problem?</h3>
<p>Users might assume that their underlying data is reflecting a highly precise measurement of a location, but coordinates collected on a low precision might be unsuitable for species distribution modelling or some other study. Right now a user making a download at GBIF has no way of knowing if the big blob occurrence points they downloaded contains a gridded dataset. <strong>This is a problem</strong> because users might assume more precision <strong>than what is present in the download</strong>.</p>
</div>
<div id="how-i-quantified-griddy-ness" class="section level3">
<h3>How I quantified griddy-ness</h3>
<p>After a little bit of trial and error, I arrived at a simple dataset feature (or measure):</p>
<blockquote>
<p>Percentage of unique lat-long points
with the most common nearest neighbor distance</p>
</blockquote>
<center>
<h1>
Gridded Example
</h1>
</center>
<p><img src="https://raw.githubusercontent.com/jhnwllr/charts/master/griddedNN.gif" width="60%" height="60%"
style="display: block;margin-left: auto;margin-right: auto;"/></p>
<center>
<h1>
Random Example
</h1>
</center>
<p><img src="https://raw.githubusercontent.com/jhnwllr/charts/master/notGriddedNN.gif" width="60%" height="60%"
style="display: block;margin-left: auto;margin-right: auto;"/></p>
</div>
<div id="good-things-about-this-feature" class="section level3">
<h3>Good things about this feature:</h3>
<ul>
<li>Easy to compute</li>
<li>Easy to understand</li>
<li>Scale independent</li>
<li>Single dimensional</li>
</ul>
</div>
<div id="bad-things-about-this-feature" class="section level3">
<h3>Bad things about this feature:</h3>
<ul>
<li>Sensitive to small differences between points</li>
<li>Sensitive to small datasets</li>
</ul>
</div>
<div id="how-to-fix-the-bad-things" class="section level3">
<h3>How to fix the bad things:</h3>
<ul>
<li>Filter out small datasets</li>
<li>Round distances to nearest minimum distance (I chose 0.01 decimal degrees), which is around 1 km.</li>
<li>Filter out datasets with most common distances below the 0.01 minimum.</li>
<li>Filter out datasets with very few remaing unique lat-long points after filtering below 0.01 minimum.</li>
</ul>
<center>
<h1>
The spectrum from gridded to random
</h1>
</center>
<p><img src="/post/2018-08-14-finding-gridded-datasets_files/figure-html/unnamed-chunk-3-1.png" width="960" /></p>
</div>
<div id="most-gridded-datasets-seem-to-be-located-in-europe" class="section level3">
<h3>Most gridded datasets seem to be located in Europe</h3>
<p><img src="https://raw.githubusercontent.com/jhnwllr/charts/master/whereGriddedLocated.gif" width="80%" height="80%"
style="display: block;margin-left: auto;margin-right: auto;"/></p>
</div>
<div id="results" class="section level2">
<h2>Results</h2>
<ul>
<li>There are around <strong>400</strong> gridded datasets within GBIF.</li>
<li>This represents around <strong>10% of the 4000 large datasets</strong> (&gt; 20 unique lat-long points)</li>
<li><strong>France publishes the most gridded datasets</strong> with 228 gridded datasets.</li>
<li>Not all rasterized or gridded datasets are a perfect square and there is a spectrum of griddyness.</li>
<li>At least <strong>75M</strong> occurrence records are gridded above 0.01 degrees.</li>
<li>Most datasets (370) are <strong>gridded at 0.1°</strong> and only <strong>12 datasets are gridded at greater than 0.40°</strong> and 33 datasets are gridded <strong>below 0.1°</strong>.</li>
</ul>
</div>
<div id="you-can-manually-review-all-datasets-that-passed-my-filters" class="section level2">
<h2>You can manually review all datasets that passed my filters</h2>
<p>I have also plotted each of the datasets that have passed some basic filters <a href="https://github.com/jhnwllr/griddedDatasets/blob/master/pdf/reviewGriddedPlots.pdf">here</a>. Around <strong>530</strong> datasets are large enough and well sampled enough to review.</p>
<pre class="r"><code>library(dplyr)

# first load the griddedDataSets.csv
urlFile = &#39;https://raw.githubusercontent.com/jhnwllr/griddedDatasets/master/csv/griddedDataSets.csv&#39;
griddedDataSets = read.table(url(urlFile),header=TRUE,sep=&quot;\t&quot;,fill=TRUE,quote=&quot;&quot;)

griddedDataSets = 
griddedDataSets %&gt;% 
filter(countNN &gt; 30) %&gt;% # only get datasets with a reasonable count of NN distances 
filter(distanceNN &gt; 0.02) # filter out distances close to minimum 0.01 (important!)
nrow(griddedDataSets) # datasets in the pdf</code></pre>
</div>
<div id="i-want-to-filter-gridded-datasets-from-my-download" class="section level2">
<h2>I want to filter gridded datasets from my download!</h2>
<p>I have processed all occurrence datasets in GBIF and produced a griddyness score for each based off of nearest neighbor distances (described above).</p>
<div id="disclaimers" class="section level3">
<h3>disclaimers</h3>
<ul>
<li>Only datasets with <strong>more than 20 unique</strong> lat-long points were processed.</li>
<li>Datasets were downloaded in <strong>August of 2018</strong>, so new datasets might not be in the csv.</li>
<li><strong>Mixed datasets</strong> might not be caught unless a large percentage of points are gridded.</li>
<li>Only the <strong>first 1000 points</strong> were downloaded from each dataset, so large datasets that are gridded but only have a few unique lat-lon points will not be caught.</li>
<li>Only looked for datasets on a grid <strong>larger than 0.01</strong> decimal degrees.</li>
<li>Not all 15k occurrence datasets are capable of being classified.</li>
<li>The griddedDataSets.csv contains <strong>4698 datasets</strong> of around 15,000 occurrence datasets with various levels of griddyness.</li>
<li>Most datasets within GBIF have less than 20 unique lat-long points (from a sample of 1000 points) and are therefore difficult to classify as gridded or random.</li>
<li>Even <strong>non-gridded datasets</strong> might not necessarily have an extremely precise lat-long occurrence records.</li>
</ul>
</div>
<div id="column-definitions-for-griddeddatasets.csv" class="section level3">
<h3>Column definitions for griddedDataSets.csv</h3>
<ul>
<li>datasetKey - GBIF dataset key.</li>
<li>publishingCountry - Country that published the dataset.</li>
<li>occCount - Total number of occurrence records in the dataset.</li>
<li>datasetTitle - Title of dataset.</li>
<li>percentNN - Fraction of unique lat-long points with the most common nearest neighbor distance.</li>
<li>distanceNN - The most common nearest neighbor distance to the nearest 0.01 degrees.</li>
<li>countNN - The count of unique lat-long points with the most common nearest neighbor distance.</li>
<li>uniqueLatLon - The number of unique lat-long points in the dataset.</li>
<li>lastUpdated - When I downloaded the data from GBIF.</li>
<li>numberSampled - number of points sampled from each dataset. Will be 1000 for each.</li>
</ul>
<p>You can download the file here <a href="https://github.com/jhnwllr/griddedDatasets/blob/master/csv/griddedDataSets.csv">griddedDataSets.csv</a>.</p>
</div>
<div id="setting-the-percentnn-parameter" class="section level3">
<h3>Setting the percentNN parameter</h3>
<p>Below is a basic example of how to filter a GBIF download in R with griddedDataSets.csv. The main variable to adjust is the <strong>percentNN</strong> or fraction of unique lat-long points with the most common distance.</p>
<ul>
<li>greater than 0.75 will likely remove only gridded datasets from a download, leaving all random datasets but also many gridded datasets.</li>
<li>greater than 0.50 will remove most gridded datasets but few random.</li>
<li>greater than <strong>0.30</strong> will likely remove almost all gridded datasets (<strong>recommended</strong>).</li>
<li>lower than <strong>0.30</strong> will likely only remove mostly non-gridded datasets (too conservative).</li>
</ul>
<p><img src="/post/2018-08-14-finding-gridded-datasets_files/figure-html/unnamed-chunk-4-1.png" width="960" /></p>
</div>
</div>
<div id="r-code-to-filter-out-gridded-datasets" class="section level2">
<h2>R-code to filter out gridded datasets</h2>
<pre class="r"><code># filtering out gridded datasets

library(rgbif)
library(dplyr)

# first load the griddedDataSets.csv
urlFile = &#39;https://raw.githubusercontent.com/jhnwllr/griddedDatasets/master/csv/griddedDataSets.csv&#39;
griddedDataSets = read.table(url(urlFile),header=TRUE,sep=&quot;\t&quot;,fill=TRUE,quote=&quot;&quot;)

griddedDataSets = 
griddedDataSets %&gt;% 
filter(countNN &gt; 30) %&gt;% # only get datasets with a reasonable count of NN distances 
filter(percentNN &gt; 0.3) %&gt;% # only filter datasets with a high percentage 
filter(distanceNN &gt; 0.02) # filter out distances close to minimum 0.01 (important!)

# Download Data
# Emberiza bruniceps; 500 Red-headed bunting records from France
buntingData = occ_search(taxonKey = 2491521,country = &quot;FR&quot;,limit=500,return=&quot;data&quot;)

nrow(buntingData) # only total records 269 (September 2018)

unique(buntingData$datasetKey) # 4 datasets

# should find 2 gridded datasets
unique(buntingData$datasetKey) %in% griddedDataSets$datasetKey 
cleanBuntingData = buntingData[!buntingData$datasetKey %in% griddedDataSets$datasetKey,] 

# only 4 occurrence records for Emberiza bruniceps found not in gridded datasets
nrow(buntingData) </code></pre>
<div id="what-if-a-dataset-is-not-in-griddeddatasets.csv" class="section level3">
<h3>What if a dataset is not in griddedDatasets.csv?</h3>
<p>Below we can also check if any datasets were not in griddedDataSets.csv.</p>
<ol style="list-style-type: decimal">
<li>We can either choose to remove any dataset on in the csv (very conservative).</li>
<li>Or we can manually check each dataset in our data but not in the csv (recommended).</li>
</ol>
<p>In this case we see that there is one dataset in our download that is not in griddedDataSets.csv.</p>
<pre class="r"><code># were any datasets downloaded that were not in the gridded datasets csv? 
load(&quot;C:/Users/ftw712/Desktop/griddedDataSets.rda&quot;)

# If the dataset is not in the 
unique(buntingData$datasetKey)[!unique(buntingData$datasetKey) %in% griddedDataSets$datasetKey]

# 1 dataset not in griddedDataSets.csv
# 906b2d3f-dbd7-4c5c-acfc-c572c35c2b5a</code></pre>
<p>We can plot the dataset <strong>not in griddedDataSets.csv</strong> using the <a href="https://www.gbif.org/developer/maps">GBIF map api</a> and see it is also most likely gridded. This illustrates that not all gridded datasets will necessarily be caught by my algorithm described above, but it should be able to remove the vast majority of gridded datasets. In the case of this dataset, it was not caught because it happens to be very large and have very few unique lat-lon points.</p>
<pre class="r"><code>library(leaflet)

prefix = &#39;https://api.gbif.org/v2/map/occurrence/density/{z}/{x}/{y}@1x.png?&#39;
query = &#39;style=classic.poly&amp;bin=hex&amp;hexPerTile=30&amp;datasetKey=906b2d3f-dbd7-4c5c-acfc-c572c35c2b5a&#39;
tile = paste0(prefix,query)

leaflet() %&gt;%
setView(lng = 5.4265362, lat = 43.4200248, zoom = 08) %&gt;%
addTiles() %&gt;%  
addTiles(urlTemplate=tile)</code></pre>
<center>
<h3>
gridded dataset not in griddedDataSets.csv
</h3>
</center>
<div id="htmlwidget-1" style="width:768px;height:288px;" class="leaflet html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"options":{"crs":{"crsClass":"L.CRS.EPSG3857","code":null,"proj4def":null,"projectedBounds":null,"options":{}}},"setView":[[43.4200248,5.4265362],8,[]],"calls":[{"method":"addTiles","args":["//{s}.tile.openstreetmap.org/{z}/{x}/{y}.png",null,null,{"minZoom":0,"maxZoom":18,"tileSize":256,"subdomains":"abc","errorTileUrl":"","tms":false,"noWrap":false,"zoomOffset":0,"zoomReverse":false,"opacity":1,"zIndex":1,"detectRetina":false,"attribution":"&copy; <a href=\"http://openstreetmap.org\">OpenStreetMap<\/a> contributors, <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">CC-BY-SA<\/a>"}]},{"method":"addTiles","args":["https://api.gbif.org/v2/map/occurrence/density/{z}/{x}/{y}@1x.png?style=classic.poly&bin=hex&hexPerTile=30&datasetKey=906b2d3f-dbd7-4c5c-acfc-c572c35c2b5a",null,null,{"minZoom":0,"maxZoom":18,"tileSize":256,"subdomains":"abc","errorTileUrl":"","tms":false,"noWrap":false,"zoomOffset":0,"zoomReverse":false,"opacity":1,"zIndex":1,"detectRetina":false}]}]},"evals":[],"jsHooks":[]}</script>
<p>In the future, I may consider downloading a larger sample from each GBIF dataset in order to catch such cases.</p>
</div>
</div>
<div id="coordiante-cleaner-r-package" class="section level1">
<h1>Coordiante Cleaner R package</h1>
<p><a href="https://azizka.github.io/CoordinateCleaner/articles/Background_dataset_level_cleaning.html">Coordiante Cleaner</a> is an R package written by Alexander Zizka. This package utilizes the <strong>cd_round</strong> function to find gridded or rasterized datasets. It uses a different methodology than what is described here, but is definitely worth taking a look at.</p>
</div>
<div id="potential-improvements" class="section level1">
<h1>Potential improvements</h1>
<div id="different-projections" class="section level3">
<h3>Different Projections</h3>
<p>Throughout this post I have implicitly been assuming all coordinates are projected using WGS84, but this might not be the case. For example, the UK uses something called <a href="https://en.wikipedia.org/wiki/Ordnance_Survey_National_Grid">Ordnance Survey National Grid</a>, and there probably other projections that might have caused me to miss a gridded dataset.</p>
</div>
<div id="multiples-of-the-most-common-distance" class="section level3">
<h3>Multiples of the most common distance</h3>
<p>One could imagine looking for multiples of the most common distance as a way of detecting gridded datasets. This has the potential to improve performance, but it might also not help very much since we will likely be finding datasets that are already very ‘griddy’ and square.</p>
</div>
<div id="gridded-datasets-not-sampled-exactly-at-the-same-point" class="section level3">
<h3>Gridded datasets not sampled exactly at the same point</h3>
<p>Near <strong>Alaska</strong> you can see that sampling seems to have occurred around the same point, <strong>but not exactly the same point</strong>.</p>
<p>```r{r, echo=FALSE, warning=FALSE,message=FALSE,fig.width=8,fig.height=3}
library(leaflet)</p>
</div>
</div>
<div id="create-the-gbif-violet-style-raster-layer" class="section level1">
<h1>create the gbif-violet style raster layer</h1>
<p>projection = ‘3857’ # projection code
style = ‘style=gbif-violet’ # style
tileRaster = paste0(‘<a href="https://tile.gbif.org/" class="uri">https://tile.gbif.org/</a>’,projection,‘/<a href="mailto:omt/%7Bz%7D/%7Bx%7D/%7By%7D@1x.png" class="email">omt/{z}/{x}/{y}@1x.png</a>?’,style)
# create our polygons layer
prefix = ‘<a href="https://api.gbif.org/v2/map/occurrence/density/%7Bz%7D/%7Bx%7D/%7By%7D@1x.png" class="uri">https://api.gbif.org/v2/map/occurrence/density/{z}/{x}/{y}@1x.png</a>?’
polygons = ‘style=classic.poly&amp;bin=hex&amp;hexPerTile=70’ # ploygon styles
datasetKey = ‘datasetKey=4fa7b334-ce0d-4e88-aaae-2e0c138d049e’ # eBird key
tilePolygons = paste0(prefix)</p>
</div>
<div id="plot-the-styled-map" class="section level1">
<h1>plot the styled map</h1>
<p>leaflet() %&gt;%
setView(lng = -151.6040, lat = 60.3609, zoom = 04) %&gt;%
addTiles(urlTemplate=tileRaster) %&gt;%
addTiles(urlTemplate=tilePolygons)
```</p>
<div id="looking-for-gridded-datasets-spaced-smaller-than-0.01-degrees" class="section level3">
<h3>Looking for gridded datasets spaced smaller than 0.01 degrees</h3>
<p>There are probably many gridded datasets at smaller than 0.01 degrees. I chose not to look for these datasets since most environmental and climate data are at a resolution equal to or higher than 0.01 degrees.</p>
</div>
<div id="sampling-more-than-1000-records-from-each-dataset" class="section level3">
<h3>Sampling more than 1000 records from each dataset</h3>
<p>Probably the main issue preventing me finding all gridded datasets is low sampling. Large gridded datasets, but with very few unique lat-long points, will not be well sampled enough at 1000 records. <strong>Probably higher sampling will locate more datasets</strong>.</p>
</div>
<div id="computing-griddy-ness-scores-for-a-new-download-expensive" class="section level3">
<h3>Computing griddy-ness scores for a new download (expensive)</h3>
<p>One might want to compute griddy-ness scores for a new download. Or we might want to increase the sampling of the datasets to be more confident that we are catching all gridded datasets. This can be done in pricipal using <a href="https://cran.r-project.org/web/packages/rgbif/index.html">rgbif</a>. In general though this process will take longer and <strong>might be difficult to acheive if there are very many datasets</strong>.</p>
<pre class="r"><code>library(rgbif)
library(dplyr) 

# Function to compute nearest neighbor features for a new download
# D - input data from a GBIF download
# key - focal key 
# k - number of nearest neighbors to compute 

getNNFeature = function(D,key,k) { # nearest neighbor features 
  D = D %&gt;% filter(datasetKey == key)
  
  # nearest neighbors distances
  NN = FNN::get.knn(cbind(D$decimalLongitude,D$decimalLatitude), k=k)$nn.dist 
  
  # Nearest Neighbor Percent Feature 
  minimum = 0.01
  NN = round(NN,2) # round nearest neighbors nearest 0.01
  # adjust precision of rounding to any desired 
  # NN = plyr::round_any(NN,0.01,ceiling) 
  
  TL = apply(NN,2,table) # table list
  # distances less than minimum 
  boolL = lapply(TL,function(x) as.numeric(names(x)) &gt; minimum) 
  
  # filter out those distances less than minimum
  T = list(); for(i in 1:length(TL)) T[[i]] = TL[[i]][boolL[[i]]] 
  
  NNC = sapply(T,function(x) rev(sort(x))[1]) # NN point count
  NNPF = sapply(T,function(x) rev(sort(x))[1]/sum(x)) # NN feature 
  MCD = as.numeric(names(NNPF)) # most common distances of NN 
  
  NNF = cbind(
  rbind(NNC) %&gt;% as.data.frame() %&gt;% setNames(paste0(&quot;NNC&quot;,1:k)),
  rbind(NNPF) %&gt;% as.data.frame() %&gt;% setNames(paste0(&quot;NNPF&quot;,1:k)),
  rbind(MCD) %&gt;% as.data.frame() %&gt;% setNames(paste0(&quot;MCD&quot;,1:k))
  )
  
  NNF$key = key # add key 
  NNF$uniqueLatLon = nrow(D)
  
  return(NNF) # return the nearest neighbor feature 
}

# Download Data
# Emberiza bruniceps; 500 Red-headed bunting records from France
buntingData = occ_search(taxonKey = 2491521,country = &quot;FR&quot;,limit=500,return=&quot;data&quot;)

keys = unique(buntingData$datasetKey)
sampleSize = 2000 # change to increase the sample size 

# download a sample of data from each dataset in the download from the api 
DL = lapply(keys,function(x) {
occ_data(datasetKey=x,hasGeospatialIssue=FALSE,hasCoordinate=TRUE,limit=sampleSize)$data
}) 
occRecords = plyr::rbind.fill(DL) 

# aggregate data 
occRecords = occRecords %&gt;% 
  group_by(datasetKey) %&gt;% 
  select(decimalLatitude,decimalLongitude) %&gt;% 
  count(decimalLongitude,decimalLatitude) %&gt;% as.data.frame()


# compute the actual features 
FL = list() # feature list
for(key in keys) {
    # sometimes this feature fails because 
    # there are no points with NN dist greater than 0.01
    out=try(getNNFeature(D=occRecords,key,k=4))
        if(class(out) == &quot;try-error&quot;) next 
    FL[[key]] = out
}
F = plyr::rbind.fill(FL) # griddyness features 

griddedDataSets = F %&gt;% 
  select(key,NNPF1,MCD1,NNC1,uniqueLatLon) %&gt;%
  setNames(c(&quot;datasetKey&quot;,&quot;percentNN&quot;,&quot;distanceNN&quot;,&quot;countNN&quot;,&quot;uniqueLatLon&quot;))

# set parameters to filter with 
griddedDataSets = 
griddedDataSets %&gt;% 
filter(countNN &gt; 30) %&gt;% # only get datasets with a reasonable count of NN distances 
filter(percentNN &gt; 0.3) %&gt;% # only filter datasets with a high percentage 
filter(distanceNN &gt; 0.02) # filter out distances close to minimum 0.01 (important!)


unique(buntingData$datasetKey) %in% griddedDataSets$datasetKey 
cleanBuntingData = buntingData[!buntingData$datasetKey %in% griddedDataSets$datasetKey,] </code></pre>
<!--more-->
</div>
</div>

    </div>

    
    

    
    

    <footer class="post-footer">
      <div class="post-tags">
          
          <a href="/tags/rstats/">rstats</a>
          
          <a href="/tags/data-quality/">data quality</a>
          
          <a href="/tags/gridded-data/">gridded data</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/gbif-maps-api-using-r-and-leaflet/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Plot almost anything using the GBIF maps api</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="/post/gbif-download-trends/">
            <span class="next-text nav-default">GBIF Download Trends</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        

      </div>
    </main>

    <footer id="footer" class="footer">
      
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  
    
      
      
    
  


	  

<div id='discourse-comments'></div>

<script type="text/javascript">
  DiscourseEmbed = { discourseUrl: 'http://datablog.trydiscourse.com/',
                     discourseEmbedUrl: 'http://elegant-torvalds-f1f2a8.netlify.com/post/<%= current_page.url %>' };

  (function() {
    var d = document.createElement('script'); d.type = 'text/javascript'; d.async = true;
    d.src = DiscourseEmbed.discourseUrl + 'javascripts/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(d);
  })();
</script>  

<div class = "copyright">
<a class="theme-link" href="https://www.gbif.org/what-is-gbif">What is GBIF?</a>
<span class="division">|</span>
<a class="theme-link" href="https://www.gbif.org/developer/summary">API</a> 
<span class="division">|</span>
<a class="theme-link" href="https://www.gbif.org/faq">FAQ</a>
<span class="division">|</span>
<a class="theme-link" href="https://discourse.gbif.org/">Community-Forum</a>

</div>

<div class = "copyright"> 
<span class="theme-info">GBIF Secretariat</span> 
<span class="theme-info">Universitetsparken 15</span> 
<span class="theme-info">DK-2100 Copenhagen Ø</span> 
<span class="theme-info" >Denmark</span>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  <script type="text/javascript" src="/lib/fancybox/jquery.fancybox-3.1.20.min.js"></script>


<script type="text/javascript" src="/dist/even.min.js?v=3.2.0"></script>








</body>
</html>
