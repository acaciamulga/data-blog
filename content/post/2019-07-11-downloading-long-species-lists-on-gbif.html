---
title: Downloading occurrences from a long species lists on GBIF
author: John Waller
date: '2019-07-11'
slug: downloading-long-species-lists-on-gbif
categories:
  - GBIF
tags:
  - API
  - downloads
  - invasive species
lastmod: '2019-07-11T16:26:18+02:00'
draft: yes
keywords: []
description: ''
authors: ''
comment: no
toc: ''
autoCollapseToc: no
postMetaInFooter: no
hiddenFromHomePage: yes
contentCopyright: no
reward: no
mathjax: no
mathjaxEnableSingleDollar: no
mathjaxEnableAutoNumber: no
hideHeaderAndFooter: no
flowchartDiagrams:
  enable: no
  options: ''
sequenceDiagrams:
  enable: no
  options: ''
---



<p>Until recently it was not possible to download more than a few hundred species at the same time. This is unfortunately is still true for downloads through the portal, which are <strong>limited to around 200 taxon keys</strong> (species, genus, family, kingdom …). This is due to <strong>limitations in browser</strong> and the <a href="">http GET limit</a>. A recent change, has now made it possible to request more species names (<strong>up to 9000</strong>) in some cases through an http request.</p>
<p>I made some large downloads using this method:</p>
<ul>
<li><a href="https://www.gbif.org/occurrence/download/0009331-190621201848488">5,000 species download</a> <strong>succeeds</strong></li>
<li><a href="https://www.gbif.org/occurrence/download/0010219-190621201848488">9,000 species download</a> <strong>succeeds</strong></li>
<li><a href="https://www.gbif.org/occurrence/download/0010226-190621201848488">10,000 species download</a> <strong>fails</strong></li>
</ul>
<blockquote>
<p><strong>NOTE:</strong> If your request can easily be summarized into higher taxon groups, it still makes more sense to download just that taxon group. For example, if you just want to download all <a href="https://www.gbif.org/occurrence/search?taxon_key=789">dragonflies</a>, all <a href="https://www.gbif.org/occurrence/search?taxon_key=359">mammals</a>, or all <a href="https://www.gbif.org/occurrence/search?taxon_key=7707728">vascular plants</a>. These requests don’t require anything special.</p>
</blockquote>
<p>One potential use-case for downloading 1000s of species at a time is <a href="https://www.gbif.org/publisher/cdef28b1-db4e-4c58-aa71-3c5238c2d0b5">invasive species lists</a>. These lists are unlikely to have species that can be easily summarized into a single higher taxonomic unit (genus, family, order, class).</p>
<p>Now getting &gt;2000 many taxon keys in one download is a bit more complicated than running a simple portal search, but you would not want to enter &gt;200 scientific names by hand anyway. Below I use the <br><a href="https://www.gbif.org/dataset/6d9e952f-948c-4483-9807-575348147c7e">Belgium Invasive Species List</a>, which has 2562 names. Invasive species lists are a perfect use-case for using a large amount of taxon keys because it is hard to narrow down the list to a higher taxon rank. That is, most invasive species do not come from one big group like Birds (Aves), mammals, vascular plants ect.</p>
<p>Previously it was not possible to make such a download.</p>
<p><a href="">really long GBIF.org query</a> <strong>fails</strong></p>
<div id="step-1.-creating-your-download-request" class="section level1">
<h1>Step 1. Creating your download request</h1>
<p>Below I prepare called <code>request.json</code>. You could prepare this file any way you want. The file will end up looking like <a href="">this</a>. Make sure to change <code>YourEmail@email.com</code> and <code>YourUserName</code> the text below.</p>
<pre class="r"><code>library(dplyr)
library(stringr)

# Getting the taxon keys
species_list &lt;- read.csv(&quot;taxon.txt&quot;,sep=&quot;\t&quot;) %&gt;%
pull(taxonID) %&gt;% # get only the GBIF backbone taxon keys
str_replace_all(&quot;https://www.gbif.org/species/&quot;,&quot;&quot;) %&gt;% # clean name
paste(collapse=&quot;,&quot;)

# change creator to your GBIF user name
# change notification_address to your email
prefix = 
&#39;{
&quot;creator&quot;: &quot;YourUserName&quot;,
&quot;notification_address&quot;: [
&quot;YourEmail@email.com&quot;
],
&quot;sendNotification&quot;: true,
&quot;format&quot;: &quot;SIMPLE_CSV&quot;,
&quot;predicate&quot;: {
&quot;type&quot;: &quot;and&quot;,
&quot;predicates&quot;: [
{
&quot;type&quot;: &quot;in&quot;,
&quot;key&quot;: &quot;TAXON_KEY&quot;,
&quot;values&quot;: [&#39;

suffix = &#39;]}]}}&#39;

json_string &lt;- paste(prefix,species_list,suffix,collapse=&quot;&quot;) # combine together

# save this file somewhere to use for download request
writeLines(json_string,file(&quot;request.json&quot;))
</code></pre>
<p>You can download <code>request.json</code> <a href="">here</a>.</p>
</div>
<div id="step-2.-make-the-request" class="section level1">
<h1>Step 2. Make the request</h1>
<p>Now we can use <code>httr</code> to start the download.</p>
<pre class="r"><code>library(httr)
library(dplyr)

user = &quot;&quot; # fill in your username
pwd = &quot;&quot; # fill in your password
email = &quot;&quot; # fill in your email
url = &quot;http://api.gbif.org/v1/occurrence/download/request&quot;

POST(url = url, 
config = authenticate(user, pwd), 
add_headers(&quot;Content-Type: application/json&quot;),
body = upload_file(&quot;request.json&quot;), # path to your local file
encode = &#39;json&#39;) %&gt;% 
content(as = &quot;text&quot;)

# &quot;0011213-190621201848488&quot; # id number</code></pre>
<p>If you are logged in you can go <a href="https://www.gbif.org/occurrence/download/">here</a> to see your download. This is the link to the download I made: <br> <a href="https://www.gbif.org/occurrence/download/0011213-190621201848488" class="uri">https://www.gbif.org/occurrence/download/0011213-190621201848488</a>. Your download will have a different id number.</p>
<p>You could also use <code>curl</code> directly if you prefer to do that.</p>
<pre><code>curl --include --user user:password --header &quot;Content-Type: application/json&quot; --data @request.json http://api.gbif.org/v1/occurrence/download/request
</code></pre>
<blockquote>
<p><strong>NOTE:</strong> As of the writing of this post, I have not gotten a <strong>rgbif::occ_download()</strong> to make a long species list download.</p>
</blockquote>
<p>This is because <code>rgbif</code> does not use the IN() predicate, which saves space.</p>
<pre><code></code></pre>
<!--more-->
</div>
